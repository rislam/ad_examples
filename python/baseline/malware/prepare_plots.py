import numpy as np
import matplotlib
matplotlib.use('Agg')
import time

from sklearn.ensemble import RandomForestClassifier
from math import floor
from common.utils import *
import matplotlib.pyplot as plt
from baseline.malware.baseline_util import *
from baseline.malware.baseline_experiments import process_options
from os import listdir
from os.path import isfile, join
from numpy import genfromtxt
from aad.data_stream import *
from baseline.malware.baseline_experiments import MalwareDataStream

def collect_results(opts, adr=False, f1=False, queried=False):
    if f1 is True:
        key = "f1.txt"
    elif adr is True:
        key = "adr.txt"
    elif queried is True:
        key = "queried.txt"
    res_dir = os.path.join(opts.save_results_location, opts.prefix)
    result_files = [f for f in listdir(res_dir) if isfile(join(res_dir, f)) and key in f]
    # print (result_files)

    if f1 is True or adr is True:
        map_mean = {}
        map_std = {}
        print("#of files ", len(result_files))
        for file in result_files:
            act_loc = os.path.join(res_dir, file)

            n_key = len(opts.prefix)
            key = file.replace(".txt", "")[n_key + 1:]
            print(key)
            r = genfromtxt(act_loc, delimiter=',')
            # print (r)
            # print(r.shape)
            # print(opts)
            mean = np.mean(r, axis=0)
            std = np.std(r, axis=0)

            if key not in map_mean.keys():
                map_mean[key] = mean
            if key not in map_std.keys():
                map_std[key] = std
        # print("###########################")
        # print (map_mean.keys(), map_mean)
        # print("###########################")
        return map_mean, map_std
    elif queried is True:
        for file in sorted(result_files):
            act_loc = os.path.join(res_dir, file)
            print("#reading file: ", file)
            n_key = len(opts.prefix)
            key = file.replace(".txt", "")[n_key + 1:]
            print(key)
            r = genfromtxt(act_loc, delimiter=',')
            print(r.shape)
            diversity_in_queries(r, opts)
            query_baseline(opts, r)


def query_baseline(opts, queries=None):
    """Compute the query Baseline"""
    datafile = opts.datafile
    label_path = datafile[:datafile.rfind("_")]
    label_file = label_path + "_orig_labels.csv"
    label_info = pd.read_csv(label_file, delimiter=',', header=0)
    labels = label_info.values[:, 1]

    for current_run_id in range(opts.n_runs):
        datafile = join(opts.filedir, "fullsamples", opts.datafile)
        opts.labelindex = 1
        X_full, y_full = read_data_as_matrix(opts)
        seed = opts.seed + current_run_id * 100
        print("seed ", seed)
        stream = MalwareDataStream(X_full, y_full, IdServer(initial=0))
        pt = stream.read_next_from_stream()
        x_init, y_init, _ = pt.x, pt.y, pt.ids
        estimator = RandomForestClassifier(n_estimators=100, random_state=seed)
        estimator.fit(x_init, y_init)
        while not stream.empty():
            i_curr = stream.read_next_from_stream()
            x, y, ids = i_curr.x, i_curr.y, i_curr.ids
            y_pred = estimator.predict_proba(x)
            data = np.hstack((x, y.reshape(-1, 1), ids.reshape(-1, 1)))
            # print ("data shape ", data.shape)
            result = np.hstack((y_pred[:, 1].reshape(-1, 1), y.reshape(-1, 1), ids.reshape(-1, 1)))
            result = result[result[:, 0].argsort()[::-1]]
            n_anomalies = np.sum(result[:, 1], axis=0)
            adr_result = np.sum(result[result[:, 0] >= 0.5, 1], axis=0)
            print(adr_result, n_anomalies)
            # print("qids ", result[result[:, 0] >= 0.5, 2][:5])
            find_families_count(labels, result[result[:, 0] >= 0.5, 2])
            init_size = x_init.shape[0]
            n_pool = x.shape[0]
            if queries is not None:
                q = queries[current_run_id]
                percentage_list = [i for i in range(0, int(n_pool / 20), int(n_pool / 100))]
                for i in range(int(n_pool / 20), int(n_pool / 4) + 1, int(n_pool / 20)):
                    percentage_list.append(i)
                print(percentage_list)
                counter = 0
                for idx in q:
                    x_init = np.vstack((x_init, data[data[:, -1] == idx, :-2]))
                    y_init = np.hstack((y_init, data[data[:, -1] == idx, -2]))
                    # print(np.where(data[:, -1] == idx))
                    data = np.delete(data, np.where(data[:, -1] == idx), axis=0)
                    # y = np.delete(y, np.where(data[:, -1] == idx))[:, -2]
                    # ids = np.delete(ids, np.where(ids == idx))
                    # if not (data.shape[0] == y.shape[0] and ids.shape[0] == y.shape[0]):
                    #     print("x, y, ids " , x.shape[0], y.shape[0], ids.shape[0])
                    #     print(data[data[:, -1] == idx, -2:])
                    #     print(idx)

                    counter += 1
                    # print ("X_Y init ", x_init.shape, y_init.shape, " x, y: ", x.shape, y.shape)
                    # print("added ", x_init.shape[0] - init_size, " ", x.shape[0])
                    if counter in percentage_list:
                        # print(counter)
                        # print ("X_Y init ", x_init.shape, y_init.shape, " data: ", data.shape[0])
                        print("queried familes ", find_families_count(labels, q[:counter]))
                        estimator.fit(x_init, y_init)
                        y_pred = estimator.predict_proba(x)
                        # print(y_pred.shape[0], " ", ids.shape)
                        result = np.hstack((y_pred[:, 1].reshape(-1, 1), y.reshape(-1, 1), ids.reshape(-1, 1)))
                        result = result[result[:, 0].argsort()[::-1]]
                        n_anomalies = np.sum(result[:, 1], axis=0)
                        adr_result = np.sum(result[result[:, 0] >= 0.5, 1], axis=0)
                        # print(result[:3], adr_result, n_anomalies)
                        # print("qids ", result[result[:, 0] >= 0.5, 2][:5])
                        l = np.hstack((result[result[:, 0] >= 0.5, 2], q[:counter]))

                        print("predicted familes ", find_families_count(labels, l))



            break
        break

def find_families_count(labels, qids):
    fam_set = set()
    for qid in qids:
        fam_set.add(labels[int(qid)])
    # print("# of families ", len(fam_set))
    return len(fam_set)


def diversity_in_queries(q, opts):
    datafile = opts.datafile
    label_path = datafile[:datafile.rfind("_")]
    label_file = label_path + "_orig_labels.csv"
    label_info = pd.read_csv(label_file, delimiter=',', header=0)
    labels = label_info.values[:, 1]
    n_runs = q.shape[0]
    n_batch = 3
    sum_run = 0
    dis_fam = 0

    for r in range(n_runs):
        n_q = q[r].shape[0]
        if opts.qsname == "diverse_query_strategy":
            n_q = floor(n_q/n_batch)
            print("n_q ", n_q)
        set_count = 0
        family_set = set()
        for qidx in range(0, n_q, n_batch):
            qlabels = labels[qidx : qidx + n_batch]
            set_count += len(set(qlabels))
            family_set.update(qlabels)
        sum_run += (set_count/(n_q/n_batch))
        # print("discovered fam ", len(family_set))
        dis_fam += len(family_set)
    print(dis_fam * 1.0 /n_runs)


def plot_map(opts, result_map, std_map=None, f1=False, adr=False):
    print("inside plot map")
    starting_yr = 2012
    ending_yr = 2017
    if f1 is True:
        suffix = "-f1"
        title = "F1 Score across years"
        y_label = "F1 Score"
        x_label = "Years"
    elif adr is True:
        suffix = "-adr"
        title = "Detection Rate across years"
        y_label = "Detection Rate"
        x_label = "Years"
    keys = result_map.keys()

    for s_yr in range(starting_yr, ending_yr):
        plt_keys = list()
        plt_values = list()
        plt_stds = list()

        for e_yr in range(s_yr, ending_yr):
            res_key = str(s_yr) + "_" + str(e_yr) + suffix
            if res_key in keys:
                print(res_key, result_map[res_key])
                n_key_res = len(result_map[res_key])
                plt_keys.append(res_key.replace(suffix, "").split("_")[1])
                plt_values.append(result_map[res_key])
                plt_stds.append(std_map[res_key])
        print(plt_keys, plt_values, len(plt_keys))
        objects = plt_keys
        y_pos = np.arange(len(objects))
        performance = plt_values
        ax = plt.subplot(111)
        w = 0.1
        plt_values_np = np.array(plt_values)
        plt_stds_np = np.array(plt_stds)
        print(plt_values_np, plt_stds_np)

        ax.errorbar(y_pos, plt_values_np[:, 0], yerr=plt_stds_np[:, 0])
        print(plt_values_np[:, 0])
        plt.xticks(y_pos, objects)
        plt.xlabel(x_label)
        plt.ylabel(y_label)
        plt.title(title + "-" + str(s_yr))
        plt.show()
        # plt.savefig(os.path.join("./results", opts.prefix + "-" + str(s_yr) + suffix + ".pdf"))
        # plt.close()


def plot_feedback(opts, result_map, std_map=None, f1=False, adr=False, adapt=False, multiple=False, v_list=None, weight=False,
                  query=False):
    print("inside plot feedback")
    starting_yr = 2012
    ending_yr = 2017
    if f1 is True:
        suffix = "-f1"
        title = "F1 Score change with feedback for "
        y_label = "F1 Score"
        x_label = r"$\beta$ (% of dataset queried)"
    elif adr is True:
        suffix = "-adr"
        title = "Detection Rate change with feedback for "
        y_label = "Detection Rate"
        x_label = r"$\beta$ (% of dataset queried)"
    keys = result_map.keys()
    print(keys)

    if adapt is True:
        plt_keys = list()
        plt_values = list()
        plt_stds = list()
        for s_yr in range(starting_yr, ending_yr):
            fair_key = str(s_yr) + "_" + str(s_yr) + "_fair_eval" + suffix
            data = result_map[str(s_yr) + "_" + str(s_yr) + suffix][0]
            plt_values.append(np.insert(result_map[fair_key], 0, data))
            plt_stds.append(np.insert(std_map[fair_key], 0, 0))
            plt_keys.append(str(s_yr) + "-fair")

            optmst_key = str(s_yr) + "_" + str(s_yr) + "_optmst_eval" + suffix
            plt_values.append(np.insert(result_map[optmst_key], 0, data))
            plt_keys.append(str(s_yr) + "-optmst")
            plt_stds.append(np.insert(std_map[fair_key], 0, 0))

        objects = plt_keys
        y_pos = np.arange(0, 5, 1)
        for yidx in range(5, 26, 5):
            y_pos = np.append(y_pos, yidx)

        performance = plt_values
        ax = plt.subplot(111)
        print("n_object ", len(objects), " len plt values ", len(plt_values[0]))
        colors = ['r', 'b', 'g', 'k', 'm']
        for i in range(len(objects)):
            print(y_pos)
            print(plt_values[i])
            if "_" in plt_keys[i]:
                label = plt_keys[i].split("_")[1]
                ls = "--"
            elif "fair" in plt_keys[i]:
                ls = "-"
                label=plt_keys[i]
            else:
                label = plt_keys[i]
                ls = '--'
            if "-" in label:
                c_y = int(plt_keys[i].split("-")[0])
                if c_y == 2012:
                    c = 'c'
                elif c_y == 2013:
                    c = 'r'
                elif c_y == 2014:
                    c = 'b'
                elif c_y == 2015:
                    c = 'm'
                elif c_y == 2016:
                    c = 'g'
            ax.errorbar(y_pos, plt_values[i][y_pos], yerr=plt_stds[i][y_pos], marker='o', markersize=4,
                        linestyle=ls, label=label, c=c)
        tick_label = list()
        for ti in range(0, 5, 1):
            tick_label.append(str(ti))
        for ti in range(5, 26, 5):
            tick_label.append(str(ti))
        plt.xticks(y_pos, tick_label, fontsize=14)
        plt.yticks(np.arange(0, 1.01, 0.2), fontsize=14)
        plt.xlabel(x_label, fontsize=20)
        plt.ylabel(y_label, fontsize=20)
        # plt.title("Adaptation with the feedbacks")
        plt.legend(ncol=2, prop={'size': 13})
        # plt.show()
        plt.savefig(os.path.join("./results", opts.prefix + "-" + str(s_yr) + suffix + "-adaptation.pdf"),bbox_inches='tight')
        plt.close()
    elif multiple is True:
        plt_keys = list()
        plt_values = list()
        plt_stds = list()

        for s_yr in range(starting_yr, ending_yr):
            for vidx in v_list:
                fair_key = str(s_yr) + "_" + str(s_yr) + "_fair_eval" + suffix + "-" + str(vidx)
                data = result_map[str(s_yr) + "_" + str(s_yr) + suffix + "-" + str(vidx)][0]
                plt_values.append(np.insert(result_map[fair_key], 0, data))
                plt_stds.append(np.insert(std_map[fair_key], 0, 0))
                plt_keys.append(str(s_yr) + "-fair" + "-" + str(vidx))

            # optmst_key = str(s_yr) + "_" + str(s_yr) + "_optmst_eval" + suffix + "-" + str(vidx)
            # plt_values.append(np.insert(result_map[optmst_key], 0, data))
            # plt_keys.append(str(s_yr) + "-optmst")
            # plt_stds.append(np.insert(std_map[fair_key], 0, 0))

        objects = plt_keys
        # y_pos = np.arange(0, 26)
        y_pos = np.arange(0, 5, 1)
        for yidx in range(5, 26, 5):
            y_pos = np.append(y_pos, yidx)
        performance = plt_values
        ax = plt.subplot(111)
        print("n_object ", len(objects), " len plt values ", len(plt_values[0]))
        print("plt keys ", plt_keys)
        colors = ['r', 'b', 'g', 'k', 'm', 'y', 'c', 'peru', 'orchid', 'lime']

        for i in range(len(objects)):
            print(y_pos)
            print(plt_values[i])
            if "fair" in plt_keys[i]:
                label = plt_keys[i][:plt_keys[i].rfind("-")]
                vidx = int(plt_keys[i].split("-")[-1])
                if vidx == 0:
                    ls = "--"
                    if weight is True:
                        label += "-W/O"
                    elif query is True:
                        label += "-US"
                elif vidx == 1:
                    ls = '-'
                    if weight is True:
                        label += "-W"
                    elif query is True:
                        label += "-GQ"
                elif vidx == 2:
                    ls = '--'
                    if query is True:
                        label += "-DvQ"
                # label=plt_keys[i]
            else:
                label = plt_keys[i]
                ls = '--'
            if "-" in label:
                c_y = int(plt_keys[i].split("-")[0])
                if c_y == 2012:
                    c = 'c'
                elif c_y == 2013:
                    c = 'r'
                elif c_y == 2014:
                    c = 'b'
                elif c_y == 2015:
                    c = 'm'
                elif c_y == 2016:
                    c = 'g'
            print(label)
            print("len: ", len(plt_values[i]))
            if len(plt_values[i]) == 11:
                print("diversity plot-----------------")
                y_pos = np.arange(0, 10, 1)

                print(y_pos, len(y_pos))
                ax.errorbar(y_pos, plt_values[i][:-1], yerr=plt_stds[i][:-1], marker='o', markersize=4,
                            linestyle=ls, label=label, c=c)
            else:
                ax.errorbar(y_pos, plt_values[i][y_pos], yerr=plt_stds[i][y_pos], marker='o', markersize=4,
                        linestyle=ls, label=label, c=c)
        tick_label = list()
        for ti in range(0, 5, 1):
            tick_label.append(str(ti))
        for ti in range(5, 26, 5):
            tick_label.append(str(ti))
        # for ti in range(0, 26, 1):
        #     tick_label.append(str(ti))
        plt.xticks(y_pos, tick_label, fontsize=14)
        plt.yticks(np.arange(0, 1.01, 0.2), fontsize=14)
        plt.xlabel(x_label, fontsize=20)
        plt.ylabel(y_label, fontsize=20)
        plt.ylim(0, 1)
        # plt.title("Diversed vs Uncertainty based querying scheme comparison")
        plt.legend(ncol=2, prop={'size': 13})
        # plt.show()
        plt.savefig(os.path.join("./results", opts.prefix + "-" + str(s_yr) + suffix + "-US-DQ-weighted.pdf"), bbox_inches='tight')
        # plt.savefig(os.path.join("./results", opts.prefix + "-" + str(s_yr) + suffix + "-US-DQ.pdf"))
        plt.close()
    else:  # generalizability
        for s_yr in range(starting_yr, ending_yr):
            plt_keys = list()
            plt_values = list()
            plt_stds = list()
            fair_key = str(s_yr) + "_" + str(s_yr) + "_fair_eval" + suffix
            data = result_map[str(s_yr) + "_" + str(s_yr) + suffix][0]
            plt_values.append(np.insert(result_map[fair_key], 0, data))
            plt_stds.append(np.insert(std_map[fair_key], 0, 0))
            plt_keys.append("fair")

            optmst_key = str(s_yr) + "_" + str(s_yr) + "_optmst_eval" + suffix
            plt_values.append(np.insert(result_map[optmst_key], 0, data))
            plt_keys.append("optmst")
            plt_stds.append(np.insert(std_map[fair_key], 0, 0))
            for e_yr in range(s_yr + 1, ending_yr):
                res_key = str(s_yr) + "_" + str(e_yr) + suffix
                if res_key in keys:
                    print(res_key, result_map[res_key])
                    n_key_res = len(result_map[res_key])
                    plt_keys.append(res_key.replace(suffix, ""))
                    plt_values.append(result_map[res_key])
                    plt_stds.append(std_map[res_key])

            objects = plt_keys
            # y_pos = np.arange(0, 6)
            y_pos = np.arange(0, 5, 1)
            for yidx in range(5, 26, 5):
                y_pos = np.append(y_pos, yidx)
            performance = plt_values
            ax = plt.subplot(111)
            w = 0.1
            # plt_values_np = np.array(plt_values)
            # plt_stds_np = np.array(plt_stds)
            # print(plt_values_np)


            for i in range(len(objects)):
                print(y_pos)
                print(plt_values[i])
                if "_" in plt_keys[i]:
                    label = "$\\upsilon=$" + str(plt_keys[i].split("_")[1])
                    ls = "-"

                else:
                    label = plt_keys[i]
                    ls = '--'
                    if label == 'fair':
                        c = 'darkorange'
                    else:
                        c = 'royalblue'
                if "_" in plt_keys[i]:
                    c_y = int(plt_keys[i].split("_")[1])
                    if c_y == 2013:
                        c = 'r'
                    elif c_y == 2014:
                        c = 'b'
                    elif c_y == 2015:
                        c = 'm'
                    elif c_y == 2016:
                        c = 'g'
                ax.errorbar(y_pos, plt_values[i][y_pos], yerr=plt_stds[i][y_pos], marker='o', markersize=4,
                linestyle=ls, label=label, c=c)
            # for i in range(0, n_key_res):
            #     adjusted_x = i - (n_key_res/2)
            #     ax.errorbar(y_pos + adjusted_x * w, plt_values_np[:, i], align='center', width=w, yerr=plt_stds_np[:, i])
            #     print(plt_values_np[:, i])
            tick_label = list()
            # for ti in range(0, 26, 5):
            #     tick_label.append(str(ti))
            for ti in range(0, 5, 1):
                tick_label.append(str(ti))
            for ti in range(5, 26, 5):
                tick_label.append(str(ti))
            plt.xticks(y_pos, tick_label, fontsize=18)
            plt.yticks(fontsize=18)
            plt.xlabel(x_label, fontsize=20)
            plt.ylabel(y_label, fontsize=20)
            plt.ylim(0, 1)
            # plt.title(title + str(s_yr))
            plt.legend(ncol=2, prop={'size': 18})
            # plt.show()
            plt.savefig(os.path.join("./results", opts.prefix + "-" + str(s_yr) + suffix + "-feedback.pdf"), bbox_inches='tight')
            plt.close()


def plot_results():

    start = time.time()
    opts = parse_arguments()

    opts = process_options(opts)
    configure_logger(opts)

    print("save location ", opts.save_results_location)
    f1_mean, f1_std = collect_results(opts, f1=True)
    adr_mean, adr_std = collect_results(opts, adr=True)
    # collect_results(opts, queried=True)

    # plot_map(opts, f1_mean, f1_std, f1=True)
    # plot_map(opts, adr_mean, adr_std, adr=True)
    plot_feedback(opts, f1_mean, f1_std, f1=True, adapt=True)
    plot_feedback(opts, adr_mean, adr_std, adr=True, adapt=True)
    # plot_feedback(opts, f1_mean, f1_std, f1=True)
    # plot_feedback(opts, adr_mean, adr_std, adr=True)

    end = time.time()
    logger.debug("##Finished all %d runs in %.2f min(s)##" % (opts.n_runs, (end - start) / 60.0))


def multi_plot_results():
    """When we want to compute results acorss different experiment settings"""
    opts = parse_arguments()

    if opts.vary_param == 0:
        param_change="weight"
    elif opts.vary_param == 1:
        param_change="independent"
    elif opts.vary_param == 2:
        param_change="feedbacked"

    f1_mean_map = {}
    f1_std_map = {}
    adr_mean_map = {}
    adr_std_map = {}

    if opts.vary_param == 0:
        list_of_params = [0, 1]

        for i in list_of_params:
            opts.weighted_update = i
            key = "W-" + str(opts.weighted_update)
            opts = process_options(opts)
            f1_mean, f1_std = collect_results(opts, f1=True)
            adr_mean, adr_std = collect_results(opts, adr=True)
            line_plt_map(f1_mean, key)
            f1_mean_map[key] = f1_mean
            f1_std_map[key] = f1_std
            adr_mean_map[key] = adr_mean
            adr_std_map[key] = adr_std
        plt.show()
        print(f1_mean_map)

def line_plt_map(map, prefix=None, plot=None):
    param_keys = map.keys()
    for pkey in param_keys:
        res_map = map[pkey]
        res_keys = res_map.keys()
        for key in res_keys:
            plt.plot(map[key], label=prefix + key)
    plt.legend()
    plt.show()


def compute_class_diversity():
    start = time.time()
    opts = parse_arguments()
    # qs = [2, 0]
    # f1_mean_complete = {}
    # f1_std_complete = {}
    # adr_mean_complete = {}
    # adr_std_complete = {}
    # for i in qs:
    #     opts.query_strategy = i
    #     opts = process_options(opts)
    #     configure_logger(opts)
    #     # collect_results(opts, queried=True)
    #     f1_mean, f1_std = collect_results(opts, f1=True)
    #     for k in f1_mean.keys():
    #         f1_mean_complete[k + "-" + str(i)] = f1_mean[k]
    #     for k in f1_std.keys():
    #         f1_std_complete[k + "-" + str(i)] = f1_std[k]
    #
    #     adr_mean, adr_std = collect_results(opts, adr=True)
    #     for k in adr_mean.keys():
    #         adr_mean_complete[k + "-" + str(i)] = adr_mean[k]
    #     for k in adr_std.keys():
    #         adr_std_complete[k + "-" + str(i)] = adr_std[k]
    #
    # plot_feedback(opts, f1_mean_complete, f1_std_complete, f1=True, multiple=True, v_list=qs, query=True)
    # plot_feedback(opts, adr_mean_complete, adr_std_complete, adr=True, multiple=True, v_list=qs, query=True)

    f1_mean_complete = {}
    f1_std_complete = {}
    adr_mean_complete = {}
    adr_std_complete = {}
    qs = [0, 1]
    for i in qs:
        opts.weighted_update = i
        opts = process_options(opts)
        configure_logger(opts)
        # collect_results(opts, queried=True)
        f1_mean, f1_std = collect_results(opts, f1=True)
        for k in f1_mean.keys():
            f1_mean_complete[k + "-" + str(i)] = f1_mean[k]
        for k in f1_std.keys():
            f1_std_complete[k + "-" + str(i)] = f1_std[k]

        adr_mean, adr_std = collect_results(opts, adr=True)
        print("----------------------")
        print(adr_mean)
        print("----------------------")
        for k in adr_mean.keys():
            adr_mean_complete[k + "-" + str(i)] = adr_mean[k]
        for k in adr_std.keys():
            adr_std_complete[k + "-" + str(i)] = adr_std[k]
    plot_feedback(opts, f1_mean_complete, f1_std_complete, f1=True, multiple=True, v_list=qs, weight=True)
    plot_feedback(opts, adr_mean_complete, adr_std_complete, adr=True, multiple=True, v_list=qs, weight=True)
    # end = time.time()
    # print("time needed %f" % (end-start))

# pythonw -m baseline.malware.prepare_plots --filedir "" --datafile "/Users/mislam1/Documents/RA/research-2018/ad_rakib/ad_examples/datasets/anomaly/malware-complete/fullsamples/malware-complete_1.csv" --query_strategy 0 --n_query 2000 --n_runs 10 --weighted_update 1 --starting 0 --vary_param 0

if __name__ == '__main__':
    plot_results()
    # compute_class_diversity()
    # multi_plot_results()
    # opts = parse_arguments()
    # query_baseline(opts)
    # collect_results(opts, queried=True)